{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harleyzhao/tools/blob/main/newpincone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04815d1b-44ee-4bd3-878e-fa0c3bf9fa7f",
      "metadata": {
        "tags": [],
        "id": "04815d1b-44ee-4bd3-878e-fa0c3bf9fa7f"
      },
      "source": [
        "# LangChain QA Panel App\n",
        "\n",
        "This notebook shows how to make this app:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a181568b-9cde-4a55-a853-4d2a41dbfdad",
      "metadata": {
        "tags": [],
        "id": "a181568b-9cde-4a55-a853-4d2a41dbfdad"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai chromadb tiktoken pypdf panel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unstructured"
      ],
      "metadata": {
        "id": "V2vBdwVrrfPO"
      },
      "id": "V2vBdwVrrfPO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unstructured[local-inference]"
      ],
      "metadata": {
        "id": "LM-G2Ai9r56z"
      },
      "id": "LM-G2Ai9r56z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone-client"
      ],
      "metadata": {
        "id": "l3SCbHcbt8nM"
      },
      "id": "l3SCbHcbt8nM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html\n"
      ],
      "metadata": {
        "id": "8UzIHOkEjPSk"
      },
      "id": "8UzIHOkEjPSk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9a464409-d064-4766-a9cb-5119f6c4b8f5",
      "metadata": {
        "tags": [],
        "id": "9a464409-d064-4766-a9cb-5119f6c4b8f5"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain import OpenAI, VectorDBQA\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import magic\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UnstructuredPDFLoader(\"/content/of3dfull.pdf\")"
      ],
      "metadata": {
        "id": "QLuRiKohrR1W"
      },
      "id": "QLuRiKohrR1W",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "Ai5UdRUFrqqg"
      },
      "id": "Ai5UdRUFrqqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'You have {len(data)} document(s) in your data')\n",
        "print (f'There are {len(data[0].page_content)} characters in your document')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYH8pP86tLUG",
        "outputId": "e2bd80d9-2f81-4674-98b9-cee3529a8720"
      },
      "id": "TYH8pP86tLUG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 1 document(s) in your data\n",
            "There are 220761 characters in your document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "nF7mllbos4rn"
      },
      "id": "nF7mllbos4rn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'Now you have {len(texts)} documents')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9rQ6-8ItnX3",
        "outputId": "05e1b322-268a-4c92-b5cf-f3bbca140056"
      },
      "id": "G9rQ6-8ItnX3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 225 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKbE-GBhtreU",
        "outputId": "29465e07-5e75-4b09-d9cc-e5677eea1893"
      },
      "id": "KKbE-GBhtreU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = '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'\n",
        "PINECONE_API_KEY = '65d3d5d0-7d4a-4979-9bb7-a205a8170ee6'\n",
        "PINECONE_API_ENV = 'asia-southeast1-gcp'\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "PIxr6Zq4uLkV"
      },
      "id": "PIxr6Zq4uLkV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "xxIwPzDnupNX"
      },
      "id": "xxIwPzDnupNX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize pinecone\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = \"chat\""
      ],
      "metadata": {
        "id": "fM5dmPLLuuvC"
      },
      "id": "fM5dmPLLuuvC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "N22HIRB0u4pn"
      },
      "id": "N22HIRB0u4pn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "nHSpT4civvce"
      },
      "id": "nHSpT4civvce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",temperature=0, openai_api_key=OPENAI_API_KEY,max_tokens=1000)\n",
        "chain = load_qa_chain(llm,chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "_ET0j1OJvxrj"
      },
      "id": "_ET0j1OJvxrj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"!pip和pip有什么区别\"\n",
        "docs = docsearch.similarity_search(query, k=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "pQtXXWUKv1D9"
      },
      "id": "pQtXXWUKv1D9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "3zdtZSp7u77n"
      },
      "id": "3zdtZSp7u77n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "sM6jPNQVv6au"
      },
      "id": "sM6jPNQVv6au",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "OS2twwnZsV31"
      },
      "id": "OS2twwnZsV31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are a chatbot having a conversation with a human.\n",
        "\n",
        "Given the following extracted parts of a long document and a question, create a final answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "{chat_history}\n",
        "Human: {human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\", \"context\"], \n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\", memory=memory, prompt=prompt)"
      ],
      "metadata": {
        "id": "iAwTSRgAsZM4"
      },
      "id": "iAwTSRgAsZM4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result=chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)\n",
        "print(result['output_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cNSaEHisfPQ",
        "outputId": "7250c5d5-7af1-4079-8f5b-37faa698e7f7"
      },
      "id": "0cNSaEHisfPQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!pip和pip的区别在于前者是在Jupyter Notebook等交互式环境下使用的命令，而后者是在命令行终端下使用的命令。!pip是Jupyter Notebook等环境下的特殊命令，用于安装和管理Python包和库。pip是Python的包管理工具，用于在命令行终端下安装和管理Python包和库。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "id": "d2i3BtNbvGDW"
      },
      "id": "d2i3BtNbvGDW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}